# Things included in this notebook
* Connect - 4 game environment.
* Demonstration of using deep convolutional network as a function approximator of state action values.
* Application of Bellman optimality equation in training deep-Q network.
* Importance of sampling with experience replay and comparison to AlphaGo Zero self-play algorithm.
* Agent learning from scratch to eventually winning connect - 4 with no human designed rules.

### Reference
* [David Silver Et al. 2017, Mastering the Game of Go without Human Knowledge](https://discovery.ucl.ac.uk/id/eprint/10045895/1/agz_unformatted_nature.pdf)

